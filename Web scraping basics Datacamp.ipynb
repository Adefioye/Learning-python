{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<html> </html> : the root tag, containing the main content of the HTML\n",
    "<body> </body> : the body tag, defining the body of the HTML\n",
    "<div> </div> : the div tag, defining a section of the body\n",
    "<p> </p> : several p-tags, defining paragraphs within the body"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The hlml tags such as, html, div and p tags may have attributes that give special instructions for the contents contain in the tag. The syntax is below\n",
    "\n",
    "<tag_name attribute_name = 'attribute_info'>\n",
    "\n",
    "   .. contents of the element\n",
    "\n",
    "</tag_name>\n",
    "\n",
    "A typical example would be seen below:\n",
    "\n",
    "<div id = 'unique_id', class = 'some class'>\n",
    "\n",
    " .. content of div elements\n",
    "\n",
    "</div>\n",
    "\n",
    "---The div tag can be identified by the unique identifier, id. Also, the class can be used but does not necessarily have to be unique.\n",
    "\n",
    "-- It is important to note that it is possible for the a tag to have multiple classes. an example can be seen in the div tag above, the div tag has multiple classes \"some\" and \"class\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath = '/html/body/div[2]'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- The xpath variable above tells us how the syntax of an xpath for navigating html tree looks like\n",
    "- the forward slash (/) depicts movement from one generation to another\n",
    "- the tags within the slashes define the tag elements\n",
    "- the square bracket [], allows us to drill down on specific sibling(s) in a tag element\n",
    "- xpath = '//table', the double slash (//) tells us to look forward to all future generations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for example:\n",
    " - xpath = '//table' ; directs to all generations of table elements in the entire html code\n",
    " - xpath = '/html/body/div[2]//table' ; directs to all generations of table elements which are descendants of the second div tag of the parent body element\n",
    " \n",
    " - xpath = '//span[@class=\"span-class\"]' ; this searches and returns all span elements with a class attribute of \"span-class\"\n",
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In xpath notation, the wild card character, * , helps to ignore the tag type of an html element."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@ symbol is use to represent the class attribute. @class, @id, and @href relate to class attribute"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xpath = '//p[@class=\"class-1\"]' ; this xpath string helps to find all paragraph elements in the html document with the class\n",
    "attribute of \"class-1\"\n",
    "\n",
    "xpath ='//*[@id=\"uid\"]' ; this helps to fetch all elements within the html document with the id attribute of \"uid\"\n",
    "\n",
    "xpath = '//div[@id=\"uid\"]/p[2]' ; this helps to navigate all div elements with an id attribute of \"uid\" within the html document and then hone in on all paragraph elemments that are second siblings of those div elements."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-- A useful tool that can be used the square bracket contains function is the contains function. The contains syntax is as thus\n",
    "\n",
    "contains(@attr-name, \"string-expr\"): This navigates the attributes with the specific @attr-name and matches those whose where the \"string-expr\" is a sub-string of the full attribute.\n",
    "\n",
    "Example:\n",
    "\n",
    "xpath = '//*[contains(@class, \"class-1\")]' : Descriptively, this would navigate and match all elements with @class attributes with a sub-string of \"class-1\"\n",
    "\n",
    "Examples of objects that can be matched with the xpath above are\n",
    "\n",
    "1) <p class=\"class-1\"> ... </p>\n",
    "2) <p class=\"class-1 class-2\"> ... </p>\n",
    "3) <p class=\"class-12\">  ... </p>\n",
    "\n",
    "xpath = '//*[@class=\"class-1\"]' ; this xpath only matches 1 because it only matches attributes whose entire @class sttribute is class-1\n",
    "\n",
    "-- To narrow down to the class attribute, the xpath to the element is specified followed by /@class OR //@class, to get the attribute of the specific element highlighted OR get the attributes of the future generations with that @class attribute nrespectively.\n",
    "\n",
    "-- "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CSS means cascading style sheets which determines how elements are displayed on the screen"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# / is replaced by > in CSS except at the first character\n",
    "-- In Xpath: /html/body/p\n",
    "-- In CSS:  html > body > p\n",
    "\n",
    "# // is replaced by space in CSS except the first character\n",
    "-- In Xpath: //html/body//p\n",
    "-- In CSS:  html > body  p\n",
    "\n",
    "# [N] is replaced by :nth-of-type(N)\n",
    "-- In Xpath: //div/p[2]\n",
    "-- In CSS:  div > p:nth-of-type(2)\n",
    "\n",
    "#\n",
    "-- In Xpath: 'html/body//div/p[2]'\n",
    "-- In CSS: 'html > body  div > p:nth-of-type(2)'\n",
    "\n",
    "#\n",
    "-- in Xpath: <xpath-to-element>/@attr-name\n",
    "-- in css: <css-to-element>::attr(attr-name)\n",
    "\n",
    "# \n",
    "\n",
    "-- In xpath: '//div[@id=\"uid\"]/a/@href'\n",
    "-- In css 'div#uid > a:attr(href)'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# One of the beautiful uses of CSS locators is that the it makes selecting elements by attributes such as @class, @id very simple\n",
    "\n",
    "# To select element by class the .(period) symbol is used\n",
    "-- p.class-1: this selects the paragraph element with class-1\n",
    "\n",
    "# To select element with id the #(pound/hash) symbol\n",
    "-- div#uid: this selects the div element with id equal to uid\n",
    "\n",
    "Example\n",
    "\n",
    "-- css_locator = 'div#uid > p.class-1' # Selects paragrah element with class-1 that are children of div element with uid\n",
    "-- css_locator = '.class-1'  # This selects all html elements with a class-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scrapy selector object is used to select portions of the HTML using Xpath(or so-called CSS locator). This ultimately allows us to read in HTML elements and access the inner elements(tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy import Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "html='''\n",
    "<html>\n",
    "    <body>\n",
    "        <div class=\"Hello baby shola\">\n",
    "            <p>Nasty and ugly mubarak!</p>\n",
    "        </div>\n",
    "        <p>Try to master scraping</p>\n",
    "    </body>\n",
    "</html>\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = Selector(text=html) # Selector object for extracting html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath='//p' data='<p>Nasty and ugly mubarak!</p>'>,\n",
       " <Selector xpath='//p' data='<p>Try to master scraping</p>'>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.xpath('//p') # This returns a selector list of 2 selector objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<p>Nasty and ugly mubarak!</p>', '<p>Try to master scraping</p>']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To extract the data in the selector list, the extract method is called on the list\n",
    "\n",
    "sel.xpath('//p').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<p>Nasty and ugly mubarak!</p>', '<p>Try to master scraping</p>')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.xpath('//p').extract()[0], sel.xpath('//p').extract()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chaining using xpath method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath='/html/body/div' data='<div class=\"Hello baby shola\">\\n      ...'>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.xpath('/html/body/div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath='./body/div' data='<div class=\"Hello baby shola\">\\n      ...'>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The above is same as below code implemented using chaining as they have same selector list\n",
    "\n",
    "sel.xpath('/html').xpath('./body/div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath='./div' data='<div class=\"Hello baby shola\">\\n      ...'>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dot must be put in front of subsequent xpath input args during chaining\n",
    "\n",
    "sel.xpath('/html').xpath('./body').xpath('./div')  # Dot must be p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "html='''\n",
    "<html>\n",
    "    <body>\n",
    "        <div class=\"Hello baby shola\">\n",
    "            <p>Nasty and ugly mubarak!</p>\n",
    "        </div>\n",
    "        <p>Try to master scraping</p>\n",
    "    </body>\n",
    "</html>\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = Selector(text=html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nasty and ugly mubarak!']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.xpath('/html/body/div/p/text()').extract() # To extract test within a paragraph using xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nasty and ugly mubarak!']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.css('html > body > div > p::text').extract() # To use css to obtain the same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of creating spider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The part that focuses on actual spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpiderClassName(scrapy.Spider):\n",
    "    name = 'spider_name'\n",
    "    \n",
    "    # Code for spider\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Running the spider"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Initiate a crawler process\n",
    "\n",
    "process = CrawlerProcess()\n",
    "\n",
    "# Tell the crawler, which spider to use\n",
    "\n",
    "process.crawl('my_spider')\n",
    "\n",
    "# start the crawling process\n",
    "\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpiderClassName(scrapy.Spider):\n",
    "    name = 'dcspider'\n",
    "    \n",
    "    def start_requests(self):\n",
    "        yield scrapy.Request(url = \"https://www.datacamp.com/courses/all\", callback=self.parse)\n",
    "        \n",
    "    def parse(self, response):\n",
    "        links = response.css('div.course-block > a::attr(href)').extract()\n",
    "        filepath = 'DC_links.csv'\n",
    "        with open(filepath, 'w') as f:\n",
    "            f.writelines([link + '\\n'] for link in links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class shola_spider(scrapy.Spider):\n",
    "    \n",
    "    name = \"my_first_spider\"\n",
    "    \n",
    "    def start_requests(self):\n",
    "        yield scrapy.Request(url = \"https://www.datacamp.com/courses/all\", callback=self.parse_front)\n",
    "    \n",
    "    def parse_front(self, response):\n",
    "        \n",
    "        # Narrow in on the course blocks\n",
    "        \n",
    "        course_block = response.css('div.course-block')\n",
    "        \n",
    "        # Direct to the course links\n",
    "        \n",
    "        course_links = course_block.xpath('./@href')\n",
    "        \n",
    "        # Links to follow\n",
    "        \n",
    "        links_to_follow = course_links.extract()\n",
    "        \n",
    "        # Follow the links to next parser\n",
    "        \n",
    "        for url in links_to_follow:\n",
    "            yield response.follow(url = url, callback = self.parse_pages)\n",
    "            \n",
    "    def parse_pages(self, response):\n",
    "        \n",
    "        # Direct to course title\n",
    "        \n",
    "        crs_title = response.xpath('//h1[contains(@class, \"title\")]/text()')\n",
    "        \n",
    "        # Extract and clean the course title next\n",
    "        \n",
    "        crs_title_ext = crs_title.extract_first().strip()\n",
    "        \n",
    "        # Direct to the chapter title text\n",
    "        \n",
    "        ch_titles = response.css('h4.chapter__title::text')\n",
    "        \n",
    "        # Extract and clean the chapter titles text\n",
    "        \n",
    "        ch_title_ext = [t.strip() for t in ch_titles.extract()]\n",
    "        \n",
    "        # Store this in our dictionary\n",
    "        \n",
    "        dic[crs_title_ext] = ch_title_ext\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-10 12:21:47 [scrapy.utils.log] INFO: Scrapy 2.1.0 started (bot: scrapybot)\n",
      "2020-05-10 12:21:47 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.20.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0\n",
      "2020-05-10 12:21:47 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'my_first_spider' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-0069a855e497>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprocess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCrawlerProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrawl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_first_spider\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'my_first_spider' is not defined"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess()\n",
    "\n",
    "process.crawl(my_first_spider)\n",
    "\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
